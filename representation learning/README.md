




## Embedding

- Query2box: Reasoning over Knowledge Graphs in Vector Space using Box Embeddings. (ICLR, 2020) [[paper](http://arxiv.org/abs/2002.05969)] (novel; empirical; embedding; KG; logical)
- Self-attention with Functional Time Representation Learning. (NIPS, 2019) [[paper](http://arxiv.org/abs/1911.12864)] (novel; theoretical; positional encoding; fourier; RKHS; time-aware)
- Embedding Logical Queries on Knowledge Graphs. (NIPS, 2018) [[paper](http://arxiv.org/abs/1806.01445)] (novel; seminal; theoretical; KG; logical)
- Self-Attention with Relative Position Representations. (2018) [[paper](http://arxiv.org/abs/1803.02155)] (novel; empirical; seminal; positional encoding; relative; transformer)
- **Distributed Representations of Words and Phrases and their Compositionality.** (NIPS, 2013) [[paper](http://arxiv.org/abs/1310.4546)]
- **Efficient Estimation of Word Representations in Vector Space.** (ICLR, 2013) [[paper](http://arxiv.org/abs/1301.3781)]

## Graph

- SimTeG: A Frustratingly Simple Approach Improves Textual Graph Learning. [[paper](http://arxiv.org/abs/2308.02565)]
- GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking. [[paper](http://arxiv.org/abs/2305.15066)] (emmm; empirical; graph; LLM; prompt)
- Towards Graph Foundation Models: A Survey and Beyond. [[paper](http://arxiv.org/abs/2310.11829)] (emmm, graph, LLM, survey)
- Graph Laplacian for Semi-Supervised Learning. (2023) [[paper](http://arxiv.org/abs/2301.04956)] (emmm; empirical; graph; Laplacian; semi-supervised; spectral)
- DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion. (ICLR, 2023) [[paper](http://arxiv.org/abs/2301.09474)] [[code](https://github.com/qitianwu/DIFFormer)] (novel; theoretical; diffusion; graph; GNN; spectral)
- Graph Neural Networks without Propagation. (WWW, 2023) [[paper](https://dl.acm.org/doi/10.1145/3543507.3583419)] (emmm; empirical; graph; GNN; low-rank)
- GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks. (WWW, 2023) [[paper](http://arxiv.org/abs/2302.08043)] (novel; empirical; graph; pretraining)
- Measuring the predictive heterogeneity. (ICLR, 2023) [[paper](https://arxiv.org/pdf/2304.00305.pdf)] (emmm; theoretical; MI; entropy; predictive heterogeneity)
- Graph Neural Networks for Link Prediction with Subgraph Sketching. (ICLR, 2023) [[paper](http://arxiv.org/abs/2209.15486)] (novel; theoretical; graph; subgraph; link prediction; WL)
- Rethinking the Expressive Power of GNNs via Graph Biconnectivity. (ICLR, 2023) [[paper](http://arxiv.org/abs/2301.09505)] [[code](https://github.com/lsj2408/Graphormer-GD)] (novel; seminal; theoretical; graph; WL)
- GPPT: Graph Pre-training and Prompt Tuning to Generalize Graph Neural Networks. (KDD, 2022) [[paper](https://dl.acm.org/doi/10.1145/3534678.3539249)] (emmm; empirical; graph; prompt; pretraining)
- Neural Link Prediction with Walk Pooling. (2022) [[paper](https://arxiv.org/abs/2110.04375#:~:text=We%20propose%20a%20link%20prediction%20algorithm%20based%20on,link%20by%20random%20walk%20probabilities%20of%20adjacent%20paths.)] [[code](https://github.com/DaDaCheng/WalkPooling)] (novel; empirical; graph; link prediction; subgraph)
- Graph Neural Networks Inspired by Classical Iterative Algorithms. (ICML, 2022) [[paper](http://arxiv.org/abs/2103.06064)] (novel; seminal; theoretical; graph; GNN; energy; spectral; diffusion; proximal)
- Survey on Graph Neural Network Acceleration: An Algorithmic Perspective. (2022) [[paper](http://arxiv.org/abs/2202.04822)] (survey)
- Computing Graph Neural Networks: A Survey from Algorithms to Accelerators. (2022) [[paper](https://dl.acm.org/doi/10.1145/3477141)] (survey) 
- GREAD: Graph Neural Reaction-Diffusion Equations. (2022) [[paper](https://arxiv-export1.library.cornell.edu/abs/2211.14208)] (novel; empirical; GNN; graph; over-smoothing; diffusion; ODE)
- How Powerful is Implicit Denoising in Graph Neural Networks. (2022) [[paper](http://arxiv.org/abs/2209.14514)] (novel; wow; theoretical; graph; GNN; denoising)
- SVD-GCN: A Simplified Graph Convolution Paradigm for Recommendation. (CIKM, 2022) [[paper](http://arxiv.org/abs/2208.12689)] (novel; theoretical; graph; GNN; smoothing)
- Releasing Graph Neural Networks with Differential Privacy Guarantees. (2022) [[paper](http://arxiv.org/abs/2109.08907)] (novel; theoretical; graph; GNN; differential privacy)
- A Survey on Graph Representation Learning Methods. [[paper](https://arxiv.org/abs/2204.01855)]
- Learning Causal Effects on Hypergraphs. (KDD, 2022) [[paper](http://arxiv.org/abs/2207.04049)] (emmm; empirical; graph; hypergraph; causal)
- Feature Overcorrelation in Deep Graph Neural Networks: A New Perspective. (KDD, 2022) [[paper](http://arxiv.org/abs/2206.07743)] [[code](https://github.com/ChandlerBang/DeCorr)] (wow; empirical; graph; over-smoothing)
- GraphMAE: Self-Supervised Masked Graph Autoencoders. (KDD, 2022) [[paper](http://arxiv.org/abs/2205.10803)] [[code](https://github.com/THUDM/GraphMAE)] (novel; empirical; graph; self-supervised)
- Elastic Graph Neural Networks. (ICML, 2022) [[paper](https://proceedings.mlr.press/v139/liu21k.html)] (novel; theoretical; robust; graph; GNN)
- PDE-GCN: Novel Architectures for Graph Neural Networks Motivated by Partial Differential Equations. (NIPS, 2021) [[paper](http://arxiv.org/abs/2108.01938)] (novel; theoretical; graph; GNN; PDE)
- MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems. (KDD, 2021) [[paper](https://ericdongyx.github.io/papers/KDD21-Huang-et-al-MixGCF.pdf)] (novel; empirical; graph; GNN; sampling)
- Interpreting and Unifying Graph Neural Networks with An Optimization Framework. (WWW, 2021) [[paper](https://dl.acm.org/doi/10.1145/3442381.3449953)] (novel; theoretical; denoising; graph; GNN)
- Graph Neural Networks with Adaptive Residual. (NIPS, 2021) [[paper](Graph Neural Networks with Adaptive Residual)] (novel; theoretical; graph; GNN)
- Towards Self-Explainable Graph Neural Network. (CIKM, 2021) [[paper](http://arxiv.org/abs/2108.12055)] [[code](https://github.com/EnyanDai/SEGNN)] (novel; empirical; graph; GNN; explainability)
- UltraGCN: Ultra Simplification of Graph Convolutional Networks for Recommendation. (CIKM, 2021) [[paper](http://arxiv.org/abs/2110.15114)] (novel; theoretical; graph; GNN, smoothing)
- GRAND: Graph Neural Diffusion. (ICML, 2021) [[paper](http://arxiv.org/abs/2106.10934)] (novel; graph; GNN; PDE)
- Inference Attacks Against Graph Neural Networks. (2021) [[paper](http://arxiv.org/abs/2110.02631)] [[code](https://github.com/Zhangzhk0819/GNN-Embedding-Leaks)] (emmm; empirical; graph; inference attacks; GNN)
- Dissecting the Diffusion Process in Linear Graph Convolutional Networks. (NIPS, 2021) [[paper](http://arxiv.org/abs/2102.10739)] (novel; theoretical; graph; GNN; diffusion; over-smoothing)
- On the Bottleneck of Graph Neural Networks and Its Practical Implications. (ICLR, 2021) [[paper](https://arxiv.org/abs/2006.05205)] [[code](https://github.com/tech-srl/bottleneck/)] (novel; empirical; graph; GNN; over-squashing)
- Understanding Structural Vulnerability in Graph Convolutional Networks. (IJCAI, 2021) [[paper](http://arxiv.org/abs/2108.06280)] [[code](https://github.com/EdisonLeeeee/MedianGCN)] (novel; empirical; graph; GCN; aggregation; mean)
- Pairwise Half-graph Discrimination: A Simple Graph-level Self-supervised Strategy for Pre-training Graph Neural Networks. (IJCAI, 2021) [[paper](https://www.ijcai.org/proceedings/2021/371)] (novel; empirical; graph GNN; half-graph; self-supervised)
- A Unified View on Graph Neural Networks as Graph Signal Denoising. (CIKM, 2021) [[paper](https://dl.acm.org/doi/10.1145/3459637.3482225)] [[code](https://github.com/alge24/ADA-UGNN)] (seminal; novel; theoretical; graph; GNN; denoising)
- GPT-GNN: Generative Pre-Training of Graph Neural Networks. (KDD, 2020) [[paper](http://arxiv.org/abs/2006.15437)] (novel; empirical; graph; pretraining)
- Inductive Representation Learning on Temporal Graphs. (ICLR, 2020) [[paper](http://arxiv.org/abs/2002.07962)] (emmm; empirical; fourier; graph; positional encoding; time-aware)
- Structpool: structured graph pooling via conditional random fields. (ICLR, 2020) [[paper](https://openreview.net/pdf?id=BJxg_hVtwH)] [[code](https://github.com/Nate1874/StructPool)] (novel; empirical; graph; GNN; pooling)
- Pairnorm: tackling oversmoothing in gnns. (ICLR, 2020) [[paper](https://openreview.net/forum?id=rkecl1rtwB)] [[code](https://github.com/LingxiaoShawn/PairNorm)] (emmm; empirical; graph; GCN; normalization; over-smoothing)
- A Theory of Usable Information Under Computational Constraints. (ICLR, 2020) [[paper](http://arxiv.org/abs/2002.10689)] (wow; seminal; entropy; MI)
- Graph Neural Networks Exponentially Lose Expressive Power for Node Classification. (ICLR, 2020) [[paper](http://arxiv.org/abs/1905.10947)] (novel; theory; graph; GNN; over-smoothing)
- Robust Graph Representation Learning via Neural Sparsification. (ICML, 2020) (emmm; empirical; graph; sparsification)
- Efficient Graph Generation with Graph Recurrent Attention Networks. (NIPS, 2020) [[paper](http://arxiv.org/abs/1910.00760)] (novel; empirical; graph; GRU; GNN)
- Graph Information Bottleneck. (NIPS, 2020) [[paper](http://arxiv.org/abs/2010.12811)] [[code](https://github.com/snap-stanford/GIB)] (emmm; theoretical; graph; mutual information; graph; GNN)
- Reliable Graph Neural Networks via Robust Aggregation. (NIPS, 2020) [[paper](http://arxiv.org/abs/2010.15651)] (novel; theoretical; graph; GNN; robustness; adversarial)
- Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs. (NIPS, 2020) [[paper](https://arxiv.org/abs/2006.11468)] [[code](https://github.com/GemsLab/H2GCN)] (novel; theoretical; graph; GNN)
- Simple and Deep Graph Convolutional Networks. (ICML, 2020) [[paper](http://arxiv.org/abs/2007.02133)] [[code](https://github.com/chennnM/GCNII)] (novel; theoretical; graph; GNN; over-smoothing)
- DropEdge: Towards Deep Graph Convolutional Networks on Node Classification. (ICLR, 2020) [[paper](http://arxiv.org/abs/1907.10903)] [[code](https://github.com/DropEdge/DropEdge)] (graph; over-smoothing; dropout)
- Graph Normalizing Flows. (NIPS, 2019) [[paper](http://arxiv.org/abs/1905.13177)] (novel; empirical; graph; flow)
- Adversarial Attacks on Graph Neural Networks via Meta Learning. (ICLR, 2019) [[paper](https://arxiv.org/abs/1902.08412)] (novel; empirical; graph; adversarial; attacks; meta-learning)
- Graph Convolutional Networks with EigenPooling. (KDD, 2019) [[paper](https://dl.acm.org/doi/10.1145/3292500.3330982)] [[code](https://github.com/alge24/eigenpooling)] (novel; wow; empirical; spectral; GCN; pooling)
- Representation Learning for Attributed Multiplex Heterogeneous Network. (KDD, 2019) [[paper](https://dl.acm.org/doi/10.1145/3292500.3330964)] [[code](https://github.com/cenyk1230/GATNE)] (emmm; empirical; heterogeneous; graph; GNN)
- Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks. (KDD, 2019) [[paper](https://dl.acm.org/doi/10.1145/3292500.3330925)] [[code](https://github.com/google-research/google-research/tree/master/cluster_gcn)] [[PyTorch](https://github.com/benedekrozemberczki/ClusterGCN)] (novel; empirical; fast; mini-batch; sampling; graph; GNN)
- Invariant and Equivariant Graph Networks. (ICLR, 2019) [[paper](https://arxiv.org/pdf/1812.09902.pdf)] (novel; theoretical; graph; GNN; invariant; equivariant)
- On the equivalence between graph isomorphism testing and function approximation with GNNs. (NIPS, 2019) [[paper](https://proceedings.neurips.cc/paper/2019/file/71ee911dd06428a96c143a0b135041a4-Paper.pdf)] [[code](https://github.com/leichen2018/Ring-GNN)] (novel; theory; graph; GNN; WL; approximation theory)
- Layer-Dependent Importance Sampling for Training Deep and Large Graph Convolutional Networks. (NIPS, 2019) [[paper](https://proceedings.neurips.cc/paper/2019/file/91ba4a4478a66bee9812b0804b6f9d1b-Paper.pdf)] [[code](https://github.com/UCLA-DM/LADIEShttps://github.com/UCLA-DM/LADIES)] (novel; theoretical; fast; graph; importance sampling)
- Heterogeneous Deep Graph Infomax. (2019) [[paper](http://arxiv.org/abs/1911.08538)] [[code](https://github.com/YuxiangRen/Heterogeneous-Deep-Graph-Infomax)] (emmm; empirical; GNN; graph; heterogeneous)
- Heterogeneous Graph Attention Network. (WWW, 2019) [[paper](https://dl.acm.org/doi/10.1145/3308558.3313562)] [[code](https://github.com/Jhy1993/HAN)] (novel; empirical; attention; GNN; graph; heterogeneous)
- Revisiting Graph Neural Networks: All We Have is Low-Pass Filters. (NIPS, 2019) [[paper](Revisiting Graph Neural Networks: All We Have is Low-Pass Filters)] (novel; theoretical; smoothness; graph; GNN; low-pass)
- Diffusion Improves Graph Learning. (NIPS, 2019) [[paper](http://arxiv.org/abs/1911.05485)] (novel; empirical; graph; GNN; diffusion)
- Simplifying Graph Convolutional Networks. (ICML, 2019) [[paper](Simplifying Graph Convolutional Networks)] [[code](https://github.com/Tiiiger/SGC)] (graph; novel; GNN; empirical; SGC)
- How Powerful are Graph Neural Networks? (ICLR, 2019) [[paper](http://arxiv.org/abs/1810.00826)] [[code](https://github.com/weihua916/powerful-gnns)] (wow; seminal; theoretical; graph; WL-Test)
- Predict then Propagate: Graph Neural Networks meet Personalized PageRank. (2019) [[paper](http://arxiv.org/abs/1810.05997)] (random walk; PageRank)
- IntentGC: A Scalable Graph Convolution Framework Fusing Heterogeneous Information for Recommendation (KDD, 2019) [[paper](https://dl.acm.org/doi/10.1145/3292500.3330686)] (emmm; empirical; graph; large-scale)
- FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling. (ICLR, 2018) [[paper](http://arxiv.org/abs/1801.10247)] (novel; wow; seminal; theoretical; graph; importance sampling)
- Embedding Temporal Network via Neighborhood Formation. (KDD, 2018) [[paper](https://dl.acm.org/doi/10.1145/3219819.3220054)] (empirical; novel; Hawkes Process; graph; dynamic)
- Beyond Link Prediction: Predicting Hyperlinks in Adjacency Space. (AAAI, 2018) [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/11780)] [[code](https://github.com/muhanzhang/HyperLinkPrediction)] (novel; theoretical; hyperlink; EM)
- An End-to-End Deep Learning Architecture for Graph Classification. (AAAI, 2018) [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/11782)] (emmm; empirical; coloring; GNN; graph; WL)
- Representation Learning on Graphs with Jumping Knowledge Networks. (ICML, 2018) [[paper](http://proceedings.mlr.press/v80/xu18c/xu18c.pdf)] (GCN; graph; novel; over-smoothing)
- Stochastic Training of Graph Convolutional Networks with Variance Reduction. (ICML, 2018) [[paper](https://arxiv.org/pdf/1710.10568)] (emmm; empirical; fast; GCN; graph; mini-batch)
- Link Prediction Based on Graph Neural Networks. (NIPS, 2018) [[paper](https://arxiv.org/abs/1802.09691)] [[code](https://github.com/muhanzhang/SEAL)] (emmm; theoretical; graph; subgrpah; link prediciton)
- Graph Attention Networks. (ICLR, 2018) [[paper](http://arxiv.org/abs/1710.10903)] [[code](https://github.com/PetarV-/GAT)] (novel; seminal; empirical; graph; attention)
- Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. (AAAI, 2018) [[paper](http://arxiv.org/abs/1801.07606)] (讲了之前 GCN 的弊端, normalzied Laplacian 矩阵 特征值:[-1, 1])
- Dynamic Network Embedding by Modeling Triadic Closure Process. (AAAI, 2018) [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/11257)] [[code](https://github.com/luckiezhou/DynamicTriad)] (emmm; graph; dynamic; empirical)
- Weighted Nonlocal Laplacian on Interpolation from Sparse Data. (2017) [[paper](http://link.springer.com/10.1007/s10915-017-0421-z)]
- Weisfeiler-Lehman Neural Machine for Link Prediction. (KDD, 2017) [[paper](https://dl.acm.org/doi/10.1145/3097983.3097996)] [[code](https://github.com/muhanzhang/LinkPrediction)] (wow; seminal; theoretical; subgraph; graph; link prediction; WL-test)
- Neural Message Passing for Quantum Chemistry. (ICML, 2017) [[paper](https://arxiv.org/abs/1704.01212)] (seminal; MPNN; GNN; novel; empirical; graph)
- Inductive Representation Learning on Large Graphs. (NIPS, 2017) [[paper](http://arxiv.org/abs/1706.02216)] [[code](https://www.cnblogs.com/MTandHJ/p/16642400.html)] (random walk; no embeddings)
- Semi-Supervised Classification with Graph Convolutional Networks. (ICLR, 2017) [[paper](http://arxiv.org/abs/1609.02907)] [[code](https://github.com/tkipf/gcn)] (GCN, seminal)
- Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering. (NIPS, 2016) [[paper](https://proceedings.neurips.cc/paper/2016/hash/04df4d434d481c5bb723be1b6df1ee65-Abstract.html)] [[code](https://github.com/mdeff/cnn_graph)] (GCN, 切比雪夫核)
- Gated Graph Sequence Neural Networks. (ICLR, 2016) [[paper](http://arxiv.org/abs/1511.05493)] [[code](https://github.com/tangjianpku/LINE)] (emmm; empirical; graph; GRU)
- Structural Deep Network Embedding. (KDD, 2016) [[paper](https://dl.acm.org/doi/10.1145/2939672.2939753)]
- node2vec: Scalable Feature Learning for Networks. (KDD, 2016) [[paper](http://arxiv.org/abs/1607.00653)] [[code](http://snap.stanford.edu/node2vec/)] [[DGL](https://github.com/dmlc/dgl/tree/master/examples/pytorch/node2vec)] (empirical; seminal; novel; graph)
- LINE: Large-scale Information Network Embedding. (WWW, 2015) [[paper](http://arxiv.org/abs/1503.03578)] (emmm; empirical; embedding)
- Deep Convolutional Networks on Graph-Structured Data. (2015) [[paper](http://arxiv.org/abs/1506.05163)] (graph)
- Convolutional Networks on Graphs for Learning Molecular Fingerprints. (NIPS, 2015) [[paper](https://proceedings.neurips.cc/paper/2015/file/f9be311e65d81a9ad8150a60844bb94c-Paper.pdf)] (novel; seminal; graph)
- Learning with Partially Absorbing Random Walks. (NIPS, 2012) [[paper](https://proceedings.neurips.cc/paper/2012/hash/512c5cad6c37edb98ae91c8a76c3a291-Abstract.html)] (提出一种图聚类方法, 可以和很多现有方法产生联系, 但是这么定义的来源是什么?)
- Graph construction and b-matching for semi-supervised learning. (ICML, 2009) [[paper](https://dl.acm.org/doi/10.1145/1553374.1553432)] (不同图的构造方法)
- Graph transduction via alternating minimization. (ICML, 2008) [[paper](http://portal.acm.org/citation.cfm?doid=1390156.1390300)] (交替迭代半监督学习算法)
- Metropolis Algorithms for Representative Subgraph Sampling. (ICDM, 2008) [[paper](http://ieeexplore.ieee.org/document/4781123/)] (novel; theoretical; graph; MCMC; sparsification)
- Nonparametric Transforms of Graph Kernels for Semi-Supervised Learning. (NIPS)
- Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions. (ICML, 2003) [[paper](https://pages.cs.wisc.edu/~jerryzhu/pub/zgl.pdf)] (图正则算法)
- Diffusion Kernels on Graphs and Other Discrete Input Spaces. (ICML)
- Combining Graph Laplacians for Semi–Supervised Learning.
- Clustering with Multiple Graphs. (ICDM, 2009) [[paper](http://ieeexplore.ieee.org/document/5360349/)]
- Sampling from large graphs. (KDD, 2006) [[paper](https://dl.acm.org/doi/10.1145/1150402.1150479)] (novel; seminal; empirical; graph; sparsification)




## VAE

- Understanding Dataset Difficulty with $\mathcal{V}$-Usable Information. (ICML, 2022) [[paper](https://proceedings.mlr.press/v162/ethayarajh22a.html)] (novel; empirical; V-information; mutual information)
- A Bayesian Framework for Information-Theoretic Probing. (2021) [[paper](http://arxiv.org/abs/2109.03853)] (novel; theory; mutual information; Bayesian)
- Controllable Guarantees for Fair Outcomes via Contrastive Information Estimation. (AAAI, 2021) [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16931)] (novel; wow; theoretical; mutual information)
- Deep Variational Information Bottleneck. (ICLR, 2017) [[paper](http://arxiv.org/abs/1612.00410)] (novel; seminal; theoretical; VAE; mutual information)

## Sparsity

- SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models. (2023) [[paper](https://arxiv.org/abs/2211.10438)] [[code](https://github.com/mit-han-lab/smoothquant)] (novel; wow; empirical; quantization)
- The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks. (ICLR, 2019) [[paper](http://arxiv.org/abs/1803.03635)] (seminal; pruning)


## ODE

- Competitive Physics Informed Networks. (ICLR, 2022, workshop) [[paper](https://arxiv.org/pdf/2204.11144.pdf)]
- Neural Ordinary Differential Equations. (NIPS, 2018) [[paper](http://arxiv.org/abs/1806.07366)]

## Prompt

- UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question Answering Over Knowledge Graph. (ICLR, 2023) [[paper](http://arxiv.org/abs/2212.00959)] (emmm; empirical; knowledge graph; reasoning)
- GPT Understands, Too. (2021) [[paper](https://arxiv.org/pdf/2103.10385.pdf)] (empirical; novel; learnable; prompt)
- Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification. (ACL, 2022) [[paper](https://aclanthology.org/2022.acl-long.158)] [[code](https://github.com/thunlp/KnowledgeablePromptTuning)] (empirical; emmm; prompt; verbalizer)
- Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. (ACL, 2021) [[paper](http://arxiv.org/abs/2107.13586)] (prompt; PLM; survey)
- Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference. (2021) [[paper](https://aclanthology.org/2021.eacl-main.20)] [[code](https://github.com/timoschick/pet)] (empirical; novel; prompt; seminal)

## LLM

- Rethinking with Retrieval: Faithful Large Language Model Inference. (2023) [[paper](http://arxiv.org/abs/2301.00303)] (novel; empirical; CoT; LLM; NLP)
- Augmented Language Models: a Survey. (2023) [[paper](http://arxiv.org/abs/2302.07842)] (novel; survey; augmentation; retrieval)
- REALM: Retrieval-Augmented Language Model Pre-Training. (ICML, 2023) [[paper](http://arxiv.org/abs/2002.08909)] (novel; empirical; NLP; retrieval; seminal)
- Generative Pretraining in Multimodality. (2023) [[paper](http://arxiv.org/abs/2307.05222)] (emmm; empirical; LLM; Multimodality)
- LLaMA: Open and Efficient Foundation Language Models. (2023) [[paper](http://arxiv.org/abs/2302.13971)] (novel; seminal; empirical; LLM)
- Decomposed Prompting: A Modular Approach for Solving Complex Tasks. (ICLR, 2023) [[paper](http://arxiv.org/abs/2210.02406)] (emmm; empirical; LLM; NLP)
- Autoregressive Search Engines: Generating Substrings as Document Identifiers. [[paper](https://www.cnblogs.com/MTandHJ/p/17796274.html)] (novel; seminal; empirical; retrieval; LM)
- Large Language Models are Zero-Shot Reasoners. (NIPS, 2022) [[paper](http://arxiv.org/abs/2205.11916)] (emmm; empirical; CoT; LLM; NLP; zero-shot)
- Measuring and Narrowing the Compositionality Gap in Language Models. (2022) [[paper](http://arxiv.org/abs/2210.03350)] (novel; empirical; CoT; LLM; NLP; retrieval)
- Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. (NIPS, 2022) [[paper](http://arxiv.org/abs/2201.11903)] (novel; empirical; LLM; NLP; CoT)
- Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions. (2022) [[paper](http://arxiv.org/abs/2212.10509)] (novel; empirical; CoT; LLM; NLP; retrieval)
- LoRA: Low-Rank Adaptation of Large Language Models. (ICLR, 2021) [[paper](http://arxiv.org/abs/2106.09685)] (novel; seminal; empirical; LLM; fine-tuning)
- Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. (NIPS, 2020) [[paper](http://arxiv.org/abs/2005.11401)] (novel; empirical; NLP; RAG; retrieval)